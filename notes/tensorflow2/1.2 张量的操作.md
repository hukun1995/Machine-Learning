[toc]

在低阶API层次上，可以把TensorFlow当做一个增强版的numpy来使用。TensorFlow提供的方法比numpy更全面，运算速度更快，如果需要的话，还可以使用GPU进行加速。
张量的操作主要包括张量的结构操作和张量的数学运算。
张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。
张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。

### 一、张量的结构操作

#### 1.1 创建张量
**一般一维张量**
```python
a = tf.constant([1, 3, 5, 7, 9] ,dtype = tf.float32)
tf.print(a)

b = tf.range(1, 10,delta = 2)
tf.print(b)

c = tf.linspace(1, 9, 5)
tf.print(c)
```
Output:
```
[1 3 5 7 9]
[1 3 5 7 9]
[1 3 5 7 9]
```
**同值张量**
```python
a = tf.zeros([3,3])
tf.print(a)

b = tf.ones([3,3])
c = tf.zeros_like(b, dtype= tf.float32)
tf.print(b)
tf.print(c)

d = tf.fill([3,2],5)
tf.print(d)
```
Outut:
```
[[0 0 0]
 [0 0 0]
 [0 0 0]]
[[1 1 1]
 [1 1 1]
 [1 1 1]]
[[0 0 0]
 [0 0 0]
 [0 0 0]]
[[5 5]
 [5 5]
 [5 5]]
```

**常见分布随机**
```python
#均匀分布随机
tf.random.set_seed(1.0)
a = tf.random.uniform([5],minval=0,maxval=10)
tf.print(a)

#正态分布随机
b = tf.random.normal([3,3],mean=0.0,stddev=1.0)
tf.print(b)

#正态分布随机，剔除2倍方差以外数据重新生成
c = tf.random.truncated_normal((3,3), mean=0.0, stddev=1.0, dtype=tf.float32)
tf.print(c)
```
Output:
```
[1.65130854 9.01481247 6.30974197 4.34546089 2.9193902]
[[0.403087884 -1.0880208 -0.0630953535]
 [1.33655667 0.711760104 -0.489286453]
 [-0.764221311 -1.03724861 -1.25193381]]
[[-0.457012236 -0.406867266 0.728577733]
 [-0.892977774 -0.369404584 0.323488563]
 [1.19383323 0.888299048 1.25985599]]
```

**特殊矩阵**
```python
# 特殊矩阵
I = tf.eye(3,3) #单位矩阵
tf.print(I)
tf.print(" ")
t = tf.linalg.diag([1,2,3]) #对角阵
tf.print(t)
```
Output:
```
[[1 0 0]
 [0 1 0]
 [0 0 1]]
 
[[1 0 0]
 [0 2 0]
 [0 0 3]]
```

#### 2.2 索引切片
